{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis with FugueSQL on Coiled Dask Clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will discuss [fugue-sql](https://docs.dask.org/en/latest/dataframe-sql.html#does-dask-implement-sql), an abstraction layer that allows users to run SQL queries on top of Pandas, Spark, and Dask dataframes. fugue-sql is part of the broader [fugue project](https://github.com/fugue-project/fugue), which aims to be an abstaction layer for distributed compute workflows. Fugue has both a Python and SQL interface. Users can choose the engine to run on just by specifying.\n",
    "\n",
    "FugueSQL is meant for data analysts and SQL lovers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/fugue-project/fugue/master/images/logo.svg\" align=\"left\" width=\"250\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "\n",
    "client = Client(processes=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid environment image found\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e82fb0c921d4fbcaeb47d4a057e2b59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h2>coiled.Cluster</h2>'), HBox(children=(HTML(value='\\n<div>\\n  <style scoped>\\n  â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import coiled\n",
    "\n",
    "cluster = coiled.Cluster(\n",
    "    n_workers=8,\n",
    "    software=\"kvnkho/fugue-sql\",\n",
    ")\n",
    "cluster\n",
    "\n",
    "# cluster = coiled.Cluster(n_workers=10)\n",
    "# cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tls://ec2-3-16-76-19.us-east-2.compute.amazonaws.com:8786</li>\n",
       "  <li><b>Dashboard: </b><a href='http://ec2-3-16-76-19.us-east-2.compute.amazonaws.com:8787' target='_blank'>http://ec2-3-16-76-19.us-east-2.compute.amazonaws.com:8787</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>6</li>\n",
       "  <li><b>Cores: </b>24</li>\n",
       "  <li><b>Memory: </b>103.08 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tls://10.2.11.109:8786' processes=6 threads=24, memory=103.08 GB>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dask.distributed import Client\n",
    "\n",
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "fugue-sql can be imported in notebooks by using the `fugue_notebook.setup` function. This provides syntax highlighting for fugue-sql cells and allows us to use the `%%fsql` magic.\n",
    "\n",
    "At the moment, the notebook extension is only available for traditional iPython notebooks. This means syntax highlighting will fail in JupyterLab environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fugue_notebook import setup\n",
    "try:\n",
    "    setup()\n",
    "except:\n",
    "    print(\"fugue-sql will work but syntax highlighting is not yet available for JupyterLab\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Look\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we load in the NYC taxi data with dask. This is standard from other demos. Persist prevents re-reading unnecessarily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-4cafeae4266a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m            'payment_type': 'float64'},\n\u001b[1;32m      7\u001b[0m     \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"anon\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mblocksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"16 MiB\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m ).persist()\n",
      "\u001b[0;32m/opt/miniconda3/envs/fugue/lib/python3.7/site-packages/dask/base.py\u001b[0m in \u001b[0;36mpersist\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0mdask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m         \"\"\"\n\u001b[0;32m--> 256\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpersist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/fugue/lib/python3.7/site-packages/dask/base.py\u001b[0m in \u001b[0;36mpersist\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    741\u001b[0m     schedule = get_scheduler(\n\u001b[0;32m--> 742\u001b[0;31m         \u001b[0mscheduler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"scheduler\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    743\u001b[0m     )\n\u001b[1;32m    744\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/fugue/lib/python3.7/site-packages/dask/base.py\u001b[0m in \u001b[0;36mget_scheduler\u001b[0;34m(get, scheduler, collections, cls)\u001b[0m\n\u001b[1;32m   1149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"scheduler\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1151\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mget_scheduler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"scheduler\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"get\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/fugue/lib/python3.7/site-packages/dask/base.py\u001b[0m in \u001b[0;36mget_scheduler\u001b[0;34m(get, scheduler, collections, cls)\u001b[0m\n\u001b[1;32m   1139\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0mdistributed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworker\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_client\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1141\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mget_client\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1142\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m             raise ValueError(\n",
      "\u001b[0;32m/opt/miniconda3/envs/fugue/lib/python3.7/site-packages/distributed/worker.py\u001b[0m in \u001b[0;36mget_client\u001b[0;34m(address, timeout, resolve_address)\u001b[0m\n\u001b[1;32m   3304\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3305\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0maddress\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mworker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddress\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0maddress\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3306\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mworker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_client\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3308\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mClient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/fugue/lib/python3.7/site-packages/distributed/worker.py\u001b[0m in \u001b[0;36m_get_client\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   3180\u001b[0m                 \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3181\u001b[0m                 \u001b[0;32mand\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddress\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddress\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3182\u001b[0;31m                 \u001b[0;32mor\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_arg\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddress\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3183\u001b[0m             ):\n\u001b[1;32m   3184\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_client\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/fugue/lib/python3.7/site-packages/distributed/deploy/cluster.py\u001b[0m in \u001b[0;36m__eq__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__eq__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 461\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__hash__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'name'"
     ]
    }
   ],
   "source": [
    "taxi_df = dd.read_csv(\n",
    "    \"s3://nyc-tlc/trip data/yellow_tripdata_2019-01.csv\",\n",
    "    dtype={'RatecodeID': 'float64',\n",
    "           'VendorID': 'float64',\n",
    "           'passenger_count': 'float64',\n",
    "           'payment_type': 'float64'},\n",
    "    storage_options={\"anon\": True},\n",
    "    blocksize=\"16 MiB\",\n",
    ").persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is our first look at fugue-sql. Notice the `%%fsql` cell magic turns the whole cell into a SQL cell. `%%fsql dask` tells Fugue to use Dask as an execution engine. Not specifying an execution engine defaults to pandas.\n",
    "\n",
    "The Dask DataFrame (named `df`) that was previously loaded in is now accessible by this SQL cell. `fugue-sql` has all ANSI SQL keywords available, so here we show a simple `GROUP BY` and `ORDER BY`. We also use the AVG aggregate function.\n",
    "\n",
    "For iPython notebook users, syntax highlighting for SQL keywords will be available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%fsql dask\n",
    "-- This is a SQL cell\n",
    "tempdf = SELECT passenger_count, AVG(tip_amount) AS average_tip\n",
    "           FROM taxi_df\n",
    "       GROUP BY passenger_count\n",
    "\n",
    "  SELECT *\n",
    "    FROM tempdf\n",
    "ORDER BY passenger_count ASC\n",
    "   LIMIT 5\n",
    "   PRINT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basics of fugue-sql\n",
    "\n",
    "fugue-sql aims to make SQL easier to use. Some enhancements have been added. One of them is already visible above where we assigned a query to `tempdf` .\n",
    "\n",
    "For familiar Dask users, this is a delayed execution, as Dask constructs a DAG."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passing Python DataFrames to fugue-sql\n",
    "\n",
    "`fugue-sql` supports Python interoperatibility. DataFrames defined outside `%%fsql` cells can be used inside the SQL queries. In this example, we create an example DataFrame and use it inside a following `fugue-sql` code block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = pd.DataFrame({'a':[1,2,3],'b':[1,2,3]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passing fugue-sql results to Python\n",
    "\n",
    "By default, the DataFrames inside fugue-sql cells will not be accessible by Python cells (or even by succeeding fugue-sql cells). We have to use the `YIELD DATAFRAME` keyword to make a DataFrame available in memory. For significantly large DataFrames, we can use the `YIELD FILE` keyword. This saves the file in a temporary location and loads it when needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%fsql\n",
    "SELECT * \n",
    "  FROM example\n",
    " WHERE a > 1\n",
    " YIELD DATAFRAME AS filtered_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%fsql\n",
    "SELECT *\n",
    "  FROM filtered_example\n",
    " PRINT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Using filtered_example from a fugue-sql cell above\n",
    "filtered_example.as_pandas().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Save\n",
    "\n",
    "fugue-sql allows users to `LOAD` from csv/json/parquet files using Pandas and Dask under the hood. This means we can load in data, perform transformations on it, and then `SAVE` the results. This allows data analysts to work on flat files with a language they are comfortable in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%fsql\n",
    "SELECT * FROM example\n",
    "SAVE OVERWRITE \"/tmp/f.csv\" (header=TRUE)\n",
    "\n",
    "loaded_example = LOAD \"/tmp/f.csv\" (header=TRUE)\n",
    "PRINT "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jinja Templating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%fsql\n",
    "SELECT *\n",
    "  FROM example\n",
    " WHERE a = {{n}}\n",
    " PRINT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Altering Schema\n",
    "\n",
    "Note that if we don't infer the schema, Pandas loads most columns as strings. We can use `ALTER COLUMNS` to change the schema. For DataFrames with a large number of columns, we recommend using `infer_schema` and then `ALTER COLUMNS` to ensure the correct types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%fsql\n",
    "df = LOAD \"/tmp/f.csv\" (header = TRUE, infer_schema=TRUE) COLUMNS a:str, b:str\n",
    "df = ALTER COLUMNS a:int, b:str FROM df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anonymity and Inline\n",
    "\n",
    "Anonymity is when the DataFrame to perform the operation on is not specified. As a default, the output of the last operation will be used. This is a `fugue-sql` feature designed to simplify code. PRINT is an example of this.\n",
    "\n",
    "Inline statements are wrapping another SQL statement inside parenthesis so that they are evaluated first as part of an outer SQL statement. This is another option instead of assigning DataFrames into variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%fsql\n",
    "df = SELECT * FROM (LOAD \"/tmp/f.csv\" (header=TRUE))\n",
    "ALTER COLUMNS a:int, b:double\n",
    "PRINT 5 ROWS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Data Analysis\n",
    "\n",
    "Now that we have covered the basics, we will perform a simple analysis and show some more advance features such as integration Python code and utilizing the Dask execution engine more. First we start by displaying the head of our DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%fsql dask\n",
    "SELECT *\n",
    "  FROM taxi_df\n",
    " LIMIT 10 \n",
    " PRINT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seaborn_barplot(df: pd.DataFrame, x_col:str, y_col:str) -> None:\n",
    "    plt.figure(figsize=(10,6))\n",
    "    sns.barplot(df[x_col].astype('str').fillna(\"None\"), df[y_col])\n",
    "    plt.ylabel(y_col, fontsize=12)\n",
    "    plt.xlabel(x_col, fontsize=12)\n",
    "    plt.title(f\"{x_col} vs {y_col}\", fontsize=15)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%fsql dask\n",
    "SELECT payment_type, total_amount, congestion_surcharge, improvement_surcharge\n",
    "  FROM taxi_df\n",
    "SAMPLE 10 PERCENT SEED 42\n",
    "OUTPUT USING seaborn_barplot PARAMS (x_col:\"payment_type\", y_col:\"total_amount\")\n",
    "OUTPUT USING seaborn_barplot PARAMS (x_col: \"congestion_surcharge\", y_col:\"total_amount\")\n",
    "OUTPUT USING seaborn_barplot PARAMS (x_col: \"improvement_surcharge\", y_col:\"total_amount\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%fsql dask\n",
    "tempdf = SELECT total_amount, improvement_surcharge\n",
    "           FROM taxi_df\n",
    "          WHERE improvement_surcharge = 0\n",
    "          \n",
    "TAKE 5 ROWS FROM tempdf PRESORT total_amount DESC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More information\n",
    "\n",
    "Fugue is a pure abstraction layer that makes code portable across differing computing frameworks such as Pandas, Spark and Dask. It decouples logic from execution engines, allowing users to write code without worrying about the execution engine during runtime. All questions are welcome in the Slack channel.\n",
    "\n",
    "[Fugue Repo](https://github.com/fugue-project/fugue)\n",
    "\n",
    "[Fugue Slack](https://join.slack.com/t/fugue-project/shared_invite/zt-jl0pcahu-KdlSOgi~fP50TZWmNxdWYQ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
